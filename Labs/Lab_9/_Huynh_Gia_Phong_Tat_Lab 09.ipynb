{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ba85e9",
   "metadata": {},
   "source": [
    "# Huynh Gia Phong Tat (Jayden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f26ddd3",
   "metadata": {},
   "source": [
    "\n",
    "# Lab 9: Build a Log Aggregator\n",
    "\n",
    "In this lab, you will create your own log generator, build a command-line utility that scans log files, summarizes their contents, and provides insight into system behavior. Data structures to track log message levels such as `INFO`, `WARNING`, `ERROR`, and `CRITICAL`.\n",
    "\n",
    "This lab reinforces:\n",
    "- File I/O\n",
    "- Pattern recognition (regex)\n",
    "- Dictionaries and counters\n",
    "- Functions and modularity\n",
    "- Optional: CLI arguments, logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d5ee8a",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1: Create Log files (20%)\n",
    "Using the the following example log format below create a **python file** that will log errors In a structured tree format \n",
    "\n",
    "You will find examples in the folder called Logs that you can use to build your program.\n",
    "\n",
    "Remember set of logs should have a varied levels of log entries (`INFO`, `WARNING`, `ERROR`, `CRITICAL`) and tailored message types for different service components.\n",
    "You must create 5 structured logs here are some examples:\n",
    "\n",
    "    sqldb\n",
    "    ui\n",
    "    frontend.js\n",
    "    backend.js\n",
    "    frontend.flask\n",
    "    backend.flask\n",
    "\n",
    "You may use chat GPT to create sample outputs NOT THE LOGS. IE:\n",
    "\n",
    "    System failure\n",
    "    Database corruption\n",
    "    Disk failure detected\n",
    "    Database corruption\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38526c9a",
   "metadata": {},
   "source": [
    "### How I approach this\n",
    "\n",
    "I wanted my logs to look **professional**, kind of like **system logs** I’ve seen in real tools (provided by you).  \n",
    "I started by creating a **formatter** to match the exact style I was given:  \n",
    "`MM/DD + padded level + source + message`.\n",
    "\n",
    "Then, instead of making everything a **giant function**,  \n",
    "I made a **class** so I could reuse the logger setup for any component I needed.  \n",
    "I like how clean it looks now — I just pass in the `component` and `function` names,  \n",
    "and it logs exactly how I want.\n",
    "\n",
    "I also made sure everything uses `snake_case` because I’m trying to be **consistent** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec9ba30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Trying to match the RSVP Agent log format\n",
    "# Starting with a custom formatter class\n",
    "class sample_formatter(logging.Formatter):\n",
    "    def format(self, record):\n",
    "        # Format the timestamp as MM/DD HH:MM:SS\n",
    "        timestamp = datetime.fromtimestamp(record.created).strftime(\"%m/%d %H:%M:%S\")\n",
    "\n",
    "        # Pad the log level so it's always aligned\n",
    "        level = record.levelname.ljust(7)\n",
    "\n",
    "        # Build the source field with the logger name\n",
    "        source = f\":{record.name}:\"\n",
    "\n",
    "        # Combine all pieces into the final log line\n",
    "        return f\"{timestamp} {level}: {source} {record.getMessage()}\"\n",
    "\n",
    "\n",
    "# Creating a structured logger that uses the formatter above\n",
    "class structured_logger:\n",
    "\n",
    "    def __init__(self, component_name, function_name):\n",
    "        # Passing in the component and function names, just going to hold onto these for now\n",
    "        self.component_name = component_name\n",
    "        self.function_name = function_name\n",
    "\n",
    "        # Logger name needs to be unique, using both names here to make it work\n",
    "        self.logger = logging.getLogger(f\"{component_name}:{function_name}\")\n",
    "\n",
    "        # Going with DEBUG for now, I think that gives me all the log levels\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "\n",
    "        # Had to separate this into its own method to keep things cleaner\n",
    "        self._setup_handler()\n",
    "\n",
    "\n",
    "    def _setup_handler(self):\n",
    "        # Needed a folder to hold the logs so they don’t end up everywhere\n",
    "        os.makedirs(\"Logs\", exist_ok=True)\n",
    "\n",
    "        # One log file per component seemed like the easiest way to organize it\n",
    "        log_file_path = f\"Logs/{self.component_name}.Log\"\n",
    "\n",
    "        # I kept running into duplicate handlers so this check avoids that\n",
    "        if not self.logger.handlers:\n",
    "            # This part took a while to figure out — I originally had the path wrong\n",
    "            file_handler = logging.FileHandler(log_file_path)\n",
    "\n",
    "            # I finally got the formatter to apply correctly after tweaking this line\n",
    "            formatter = sample_formatter()\n",
    "            file_handler.setFormatter(formatter)\n",
    "\n",
    "            # I remember forgetting to attach this the first time — nothing was logging\n",
    "            self.logger.addHandler(file_handler)\n",
    "\n",
    "\n",
    "    def log(self, level, message):\n",
    "        # Tried a bunch of ways to get the right log method — this one worked best\n",
    "        log_method = getattr(self.logger, level.lower(), None)\n",
    "\n",
    "        # Without this check, I was getting errors when passing unknown levels\n",
    "        if log_method:\n",
    "            log_method(message)\n",
    "\n",
    "        # I thought about adding a fallback print but this felt cleaner for now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5255ab",
   "metadata": {},
   "source": [
    "\n",
    "### Example Log Format\n",
    "\n",
    "You will work with logs that follow this simplified structure:\n",
    "\n",
    "```\n",
    "2025-04-11 23:20:36,913 | my_app | INFO | Request completed\n",
    "2025-04-11 23:20:36,914 | my_app.utils | ERROR | Unhandled exception\n",
    "2025-04-11 23:20:36,914 | my_app.utils.db | CRITICAL | Disk failure detected\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3659dfbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af5f6e84",
   "metadata": {},
   "source": [
    "## Part 2: Logging the Log File (40%)\n",
    "    New File\n",
    "### Part 2a: Read the Log File (see lab 7) (10%)\n",
    "\n",
    "\n",
    "Write a function to read the contents of a log file into a list of lines. Handle file errors gracefully.\n",
    "\n",
    "### Part 2b: Parse Log Lines (see code below if you get stuck) (10%)\n",
    "\n",
    "Use a regular expression to extract:\n",
    "- Timestamp\n",
    "- Log name\n",
    "- Log level\n",
    "- Message\n",
    "\n",
    "### Part 2c: Count Log Levels (20%)\n",
    "\n",
    "Create a function to count how many times each log level appears. Store the results in a dictionary. Then output it as a Json File\n",
    "You may pick your own format but here is an example. \n",
    "```python\n",
    "{\n",
    "    \"INFO\": \n",
    "    {\n",
    "        \"Request completed\": 42, \n",
    "        \"Heartbeat OK\": 7\n",
    "    }\n",
    "\n",
    "    \"WARNING\":\n",
    "    {\n",
    "        ...\n",
    "    }\n",
    "}\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bc631f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to read the log file from: Logs\\RSVP_Agent_processing.log\n",
      "Going through 55 lines...\n",
      "Counting up the log levels and messages...\n",
      "Checking the full path just to be sure:\n",
      "    c:\\Games\\Github ETE 4990\\homeworkfolder-Jayden-gif-dev-1\\Labs\\Lab_9\\Logs\\RSVP_Agent_processing.log\n",
      "Saving everything to: Logs\\log_summary.json\n",
      "Done! Should be good to go.\n"
     ]
    }
   ],
   "source": [
    "# Paste your python file here don't for get to upload it with your submission\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from structured_logger import sample_formatter  # using the custom formatter I wrote earlier\n",
    "\n",
    "# Use this from project 1 to read the log file\n",
    "# I had to change the import path a bit to match my folder structure\n",
    "def read_log_file(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            return file.readlines()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filepath}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Couldn't read the file: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def parse_log_lines(log_lines):\n",
    "    parsed_logs = []\n",
    "# This regex is a bit of a mess but it works for now. I might clean it up later.\n",
    "# I had to change the regex a bit to match the log format\n",
    "    for line in log_lines:\n",
    "        if len(line.strip()) < 20:\n",
    "            continue\n",
    "        timestamp = line[:17].strip()\n",
    "        remainder = line[17:].strip()\n",
    "        if ':' not in remainder:\n",
    "            continue\n",
    "        level_part, rest = remainder.split(':', 1)\n",
    "        level = level_part.strip()\n",
    "        if ':' not in rest:\n",
    "            continue\n",
    "        name_part, message = rest.split(':', 1)\n",
    "        name = name_part.strip()\n",
    "        message = message.strip()\n",
    "        parsed_logs.append({\n",
    "            \"timestamp\": timestamp,\n",
    "            \"level\": level,\n",
    "            \"name\": name,\n",
    "            \"message\": message\n",
    "        })\n",
    "    return parsed_logs\n",
    "\n",
    "# This function counts the occurrences of each log level and message, and returns a summary. Took a while to get this right\n",
    "# because I was trying to use a list of tuples instead of a dictionary. This way is much cleaner.\n",
    "def count_log_levels(parsed_logs):\n",
    "    summary = defaultdict(lambda: defaultdict(int))\n",
    "    for entry in parsed_logs:\n",
    "        level = entry['level']\n",
    "        msg = entry['message']\n",
    "        summary[level][msg] += 1\n",
    "    return summary\n",
    "\n",
    "\n",
    "def main():\n",
    "    # This part is just to make sure the log file is in the right place\n",
    "    # I had to change the path a bit to match my folder structure\n",
    "    log_input_path = os.path.join(\"Logs\", \"RSVP_Agent_processing.log\")\n",
    "    log_output_path = os.path.join(\"Logs\", \"log_summary.json\")\n",
    "    print(f\"Trying to read the log file from: {log_input_path}\")\n",
    "    lines = read_log_file(log_input_path)\n",
    "    print(f\"Going through {len(lines)} lines...\")\n",
    "    parsed = parse_log_lines(lines)\n",
    "    print(\"Counting up the log levels and messages...\")\n",
    "    summary = count_log_levels(parsed)\n",
    "    # This part gave me some headaches until I realized the folder had to exist\n",
    "    os.makedirs(\"Labs/Lab_9/Logs\", exist_ok=True)\n",
    "    print(\"Checking the full path just to be sure:\")\n",
    "    print(\"   \", os.path.abspath(log_input_path))\n",
    "    print(f\"Saving everything to: {log_output_path}\")\n",
    "    with open(log_output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary, f, indent=4)\n",
    "    print(\"Done! Should be good to go.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b9e860",
   "metadata": {},
   "source": [
    "# PLEASE DON'T RUN THIS HERE JUPYTER MESSED UP THE FOLDERS AND THE DIRECTORIES."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045c30f",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3: Generate Summary Report (40%)\n",
    "    New File\n",
    "### Step 3a (20%):\n",
    " Develop a function that continuously monitors your JSON file(s) and will print a real-time summary of log activity. It should keep count of the messages grouped by log level (INFO, WARNING, ERROR, CRITICAL) and display only the critical messages. (I.e. If new data comes in the summary will change and a new critical message will be printed)\n",
    " - note: do not reprocess the entire file on each update.  \n",
    "\n",
    "### Step 3a: Use a Matplotlib (Lecture 10) (20%)\n",
    "Develop a function that continuously monitors your JSON file(s) and will graph in real-time a bar or pie plot of each of the errors.  (a graph for each log level). \n",
    "- The graph should show the distribution of log messages by level  (INFO, WARNING, ERROR, CRITICAL)  \n",
    "\n",
    "\n",
    "### Critical notes:\n",
    "- Your code mus use Daemon Threads (Lecture 14)\n",
    "- 3a and 3b do not need to run at the same time. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste your python file here \n",
    "# don't forget to upload it with your submission\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# I had issues with file paths at first — this just makes sure it works no matter where I run the script from\n",
    "base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "log_summary_path = os.path.join(base_dir, \"Logs\", \"log_summary.json\")\n",
    "\n",
    "# I use this to remember the previous state of the log\n",
    "last_snapshot = {}\n",
    "\n",
    "# This function just keeps checking the log file and prints stuff when something new happens\n",
    "def monitor_log_summary():\n",
    "    global last_snapshot\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            with open(log_summary_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Making a copy of what's in the log right now\n",
    "            new_snapshot = defaultdict(dict)\n",
    "            for level, messages in data.items():\n",
    "                for msg, count in messages.items():\n",
    "                    new_snapshot[level][msg] = count\n",
    "\n",
    "            # Only show stuff if it changed since last time\n",
    "            if new_snapshot != last_snapshot:\n",
    "                print(\"\\n--- Updated Log Summary ---\")\n",
    "                for level in new_snapshot:\n",
    "                    total = sum(new_snapshot[level].values())\n",
    "                    print(f\"{level}: {total} entries\")\n",
    "\n",
    "                    # I only really care about CRITICAL messages for now\n",
    "                    if level == \"CRITICAL\":\n",
    "                        for msg, count in new_snapshot[level].items():\n",
    "                            # Show it if it's a new critical message\n",
    "                            if msg not in last_snapshot.get(\"CRITICAL\", {}):\n",
    "                                print(f\"[CRITICAL] {msg} (x{count})\")\n",
    "\n",
    "                # Save what we just saw so we can compare it next time\n",
    "                last_snapshot = new_snapshot\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(\"[Monitor] File not found... still waiting for it to show up.\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"[Monitor] JSON error — probably still writing or got corrupted.\")\n",
    "        time.sleep(3)  # just chill for a few seconds before checking again\n",
    "\n",
    "\n",
    "# This just shows the log data as a bar chart that updates\n",
    "def visualize_log_levels():\n",
    "    plt.ion()  # this makes the chart live and auto-refresh\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            with open(log_summary_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            levels = list(data.keys())\n",
    "            counts = [sum(data[level].values()) for level in levels]\n",
    "\n",
    "            # Refresh the chart — it just wipes and redraws\n",
    "            ax.clear()\n",
    "            ax.bar(levels, counts)\n",
    "            ax.set_title(\"Log Level Distribution\")\n",
    "            ax.set_xlabel(\"Log Level\")\n",
    "            ax.set_ylabel(\"Total Messages\")\n",
    "            plt.draw()\n",
    "            plt.pause(2)  # wait a bit before checking again\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Graph] Error: {e}\")\n",
    "            time.sleep(2)\n",
    "\n",
    "\n",
    "# This gets called when I press 1 in the menu (monitor_logs.py)\n",
    "def start_monitor():\n",
    "    monitor_thread = threading.Thread(target=monitor_log_summary, daemon=True)\n",
    "    monitor_thread.start()\n",
    "    print(\"Log monitor started.\")  # Just a confirmation\n",
    "\n",
    "\n",
    "# This one is for the graph (option 2 in monitor_logs.py)\n",
    "def start_visualizer():\n",
    "    visualize_thread = threading.Thread(target=visualize_log_levels, daemon=True)\n",
    "    visualize_thread.start()\n",
    "    print(\"Visualizer started.\")  # Another confirmation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197256d8",
   "metadata": {},
   "source": [
    "# Bonus a small menu for using it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "from analyze_logs_monitor import start_monitor, start_visualizer  # I moved monitor/graph code into a separate helper file\n",
    "\n",
    "# I made this a generator because it felt cleaner than writing a giant if-else\n",
    "def menu_options():\n",
    "    yield \"1\", \"Text Summary (CRITICAL alerts)\", start_monitor\n",
    "    yield \"2\", \"Live Graph (Matplotlib)\", start_visualizer\n",
    "    yield \"q\", \"Quit\", None\n",
    "\n",
    "def main():\n",
    "    print(\"=== Log Summary Monitor ===\")\n",
    "\n",
    "    # Instead of writing a bunch of ifs, I just convert the generator to a dictionary\n",
    "    options = {key: (desc, action) for key, desc, action in menu_options()}\n",
    "\n",
    "    # Show the menu to the user\n",
    "    for key, (desc, _) in options.items():\n",
    "        print(f\"{key}. {desc}\")\n",
    "\n",
    "    # This lets me type like \" 1 \" or \"Q\" without crashing\n",
    "    choice = input(\"Choose an option: \").strip().lower()\n",
    "\n",
    "    if choice not in options:\n",
    "        print(\"Invalid choice. Exiting.\")\n",
    "        return\n",
    "\n",
    "    desc, action = options[choice]\n",
    "\n",
    "    if choice == 'q':\n",
    "        print(\"Goodbye.\")\n",
    "        return\n",
    "\n",
    "    # Once a valid choice is made, I call the action (either monitor or graph)\n",
    "    print(f\"Starting: {desc}...\\n\")\n",
    "    action()\n",
    "\n",
    "    # This used to run forever but I like this better — I just press ENTER to stop\n",
    "    try:\n",
    "        input(\"Press ENTER to stop monitoring...\\n\")\n",
    "        print(\"Stopping...\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nInterrupted by user.\")\n",
    "\n",
    "# This is just the usual Python entry point\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
